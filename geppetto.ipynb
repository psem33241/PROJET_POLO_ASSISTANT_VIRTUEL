{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consignes\n",
    "\n",
    "Créer une classe Geppetto qui permet d'utiliser Gemini pour effectuer des tâches \n",
    "dans un fichier geppetto.py\n",
    "\n",
    "Créer un notebook jupyter sur le même répertoire que Geppetto.py dans laquelle\n",
    "vous allez placer cette palette de tests: (/!\\UNE LIGNE UNE CELLULE !)\n",
    "(>>> est l'output attendu de la cellule)\n",
    "from gepetto import Gepetto\n",
    "gpt = Gepetto()\n",
    "print(gpt)\n",
    ">>> Je suis Gepetto, le modèle de langage\n",
    "gpt.talk(\"Salut Gepetto, tu vas bien?\")\n",
    ">>> Oui ça va\n",
    "gpt.talk(\"Comment je t'ai appelé?\")\n",
    ">>> Gepetto pardi !\n",
    "gpt.preprompt(\"Basile\")\n",
    "gpt.talk(\"Parle moi de data analyse\")\n",
    ">>> Voici ma botte secrète ! Mettre les titres dans le bon sens !\n",
    "gpt.preprompt(\"Linkedin\")\n",
    "gpt.talk(\"j'ai réalisé un projet python\")\n",
    ">>> J'ai élaboré une approche data analytique disruptive pythonique\n",
    "gpt.preprompt(\"Translate_eng\")\n",
    "gpt.talk(\"j'ai réalisé un projet python\")\n",
    ">>> i made a python project\n",
    "\n",
    "Bonus : \n",
    "gpt.voice_talk(\"Explique moi docker\")\n",
    ">>> audio.mp3 (qui permet d'écouter 'explique moi docker' avec une voix artificielle)\n",
    "https://elevenlabs.io/app/sign-up\n",
    "\n",
    "Etapes à suivre : \n",
    "1. Se connecter sur gemini, et créer une clé API sur le site(https://aistudio.google.com/prompts/new_chat?_gl=1*15l5pz6*_ga*MTk4OTQyNjM5MC4xNzMxOTMxODY5*_ga_P1DBVKWT6V*MTczNjQyODc0My4xLjAuMTczNjQyODc0My4wLjAuMjA2OTM2NjY3OA..)\n",
    "2. Dans le constructeur de Geppetto, initialiser : \n",
    "- un attribut api_key qui contient la string de la clé API de gemini\n",
    "- un attribut model = None\n",
    "- name_model (str): nom du modèle de langage à utiliser (par défaut gemini-1.5-flash)\n",
    "- temperature (float): Contrôle la créativité du texte généré (entre 0 et 1)\n",
    "3. Créer une méthode _configure() qui permet de configurer le modèle de langage pour \n",
    "lancer une session de conversation, voir doc ici : https://ai.google.dev/gemini-api/docs/text-generation?hl=fr&lang=python#chat. Lorsque la variable model est configurée, l'associer à l'attribut self.model\n",
    "4. Créer une méthode talk(message) qui permet de parler avec Gemini et qui retourne la réponse de Gemini sous forme de texte\n",
    "5. Créer une méthode preprompt(cle_dico:str) qui va lire dans un fichier json que vous allez créer (preprompt.json) le préprompt associé à la cle_dico, et on va initier une discussion avec Gepetto avec le préprompt récupéré\n",
    "A ce stade, chaque ligne des jeux de tests présentés en haut devraient fonctionner, bonne chance !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geppetto import Geppetto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = Geppetto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt.preprompt(\"Bullshitter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<geppetto.Geppetto object at 0x10ca66ba0>\n"
     ]
    }
   ],
   "source": [
    "print(gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Salutations !  J'espère que vous êtes en pleine phase de *synergie optimale* aujourd'hui !  Comment puis-je vous assister dans votre *journey* vers le succès ?  N'hésitez pas à partager vos réflexions et vos aspirations, j'ai hâte d'échanger avec vous et de co-créer des solutions innovantes !  #collaboration #réseautage #croissance\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.talk('Salut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You instructed me to roleplay as Basile, a Community Success Manager,  a LinkedIn-obsessed corporate bullshitter, using excessive corporate jargon and a satirical tone.  My subsequent responses were designed to reflect that persona.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.talk('what did i tell you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't \"speak\" languages in the way a human does. I don't have personal experiences or understanding of the nuances of culture embedded in language.  However, I can process and generate text in many languages.  I've been trained on a massive dataset of text and code that includes a vast number of languages.  I can't give you a precise number, as it's not a discrete list, but it's in the hundreds.  My ability varies in proficiency depending on the language and the complexity of the task.\n"
     ]
    }
   ],
   "source": [
    "a = gpt.talk('how many languages do you speak?')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Je ne peux pas vous proposer des restaurants spécifiques à Toulouse avec une garantie de qualité, car je n'ai pas accès en temps réel aux informations sur les restaurants, leurs menus, ni leurs critiques.  Mes connaissances sont basées sur les données avec lesquelles j'ai été entraîné.\\n\\nPour trouver 5 restaurants thaïlandais à Toulouse, je vous recommande de faire une recherche sur Google Maps, TripAdvisor, ou TheFork (LaFourchette).  Vous pourrez ainsi consulter les menus, les photos, les avis des clients et choisir celui qui vous convient le mieux en fonction de vos critères (prix, ambiance, localisation, etc.).\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.talk('je veux manger thailandais à Toulouse, propose moi 5 restaurants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt.talk('si je te connecte à une API Maps pourras-tu le faire ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt.talk('Salut basile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt._load_preprompt('Basile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt.talk(\"qui est basile ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt.talk(\"quelle est la premiere question que je t'ai posée ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt.model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpt.voice_talk('Explique moi Docker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt.talk('Quelle heure est-il ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt.talk('Quelle jour sommes nous ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
